{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import view_samples\n",
    "from training import train_discriminator, train_generator, make_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "celeba_train = datasets.CelebA(root='data/', download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "\n",
    "# build DataLoaders for CIFAR10 dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=celeba_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9dd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(train_loader))\n",
    "view_samples(images[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, use_batch_norm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=2,\n",
    "                              padding = 1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x) if self.use_batch_norm else x\n",
    "        return self.activation(x)\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, conv_dim=64, channels=3):  # Increased conv_dim\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            ConvBlock(channels, conv_dim, 4, use_batch_norm=False),\n",
    "            ConvBlock(conv_dim, conv_dim * 2, 4),\n",
    "            ConvBlock(conv_dim * 2, conv_dim * 4, 4),\n",
    "            ConvBlock(conv_dim * 4, conv_dim * 8, 4),  # Extra layer\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_dim * 8 * 4 * 4, 1)  # Adjusted for 64x64 output\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cef4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, use_batch_norm=True):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "                                         stride, padding, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.batch_norm(x) if self.use_batch_norm else x\n",
    "        return self.activation(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, conv_dim=64, channels=3):  # Increased conv_dim for higher res\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = nn.Sequential(\n",
    "            DeconvBlock(latent_dim, conv_dim * 8, 4, 1, 0),  # More layers for 64x64\n",
    "            DeconvBlock(conv_dim * 8, conv_dim * 4, 4, 2, 1),\n",
    "            DeconvBlock(conv_dim * 4, conv_dim * 2, 4, 2, 1),\n",
    "            DeconvBlock(conv_dim * 2, conv_dim, 4, 2, 1),\n",
    "            \n",
    "            nn.ConvTranspose2d(conv_dim, channels, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.view(x.size(0), self.latent_dim, 1, 1)\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dim = 64  # Increased for higher resolution\n",
    "latent_dim = 128  # Increase latent dimension for more expressive representations\n",
    "channels = 3\n",
    "\n",
    "discriminator = Discriminator(conv_dim, channels)\n",
    "generator = Generator(latent_dim, conv_dim, channels)\n",
    "\n",
    "gpu = torch.cuda.is_available()\n",
    "if gpu:\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 50  # Increase from 10 to 50 for better convergence\n",
    "\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for real_images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        disc_loss = train_discriminator(real_images, discriminator, disc_optimizer, \n",
    "                                        generator, latent_dim, gpu)\n",
    "        \n",
    "        # Train the generator\n",
    "        gen_loss = train_generator(discriminator, generator, gen_optimizer, batch_size, \n",
    "                                   latent_dim, gpu, channels=3)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"D Loss: {disc_loss:.4f}, G Loss: {gen_loss:.4f}\")\n",
    "    \n",
    "    # Generate and view samples\n",
    "    if (epoch + 1) % 10 == 0:  # Generate samples every 10 epochs to monitor progress\n",
    "        samples = make_samples(generator, 16, latent_dim, channels=3, gpu=gpu)\n",
    "        view_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1c129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
